<!-- Adapted from https://www.evl.uic.edu/aej/424/ -->

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <title>Virtual Reality</title>
    <link rel="shortcut icon" href="../styles/oculus.png">
    <style>
        body {
            font-size: 1.25em;
        }
    </style>
</head>
<body bgcolor="white" text="black">

<hr
        style="width: 100%; height: 1px;">
<div align="left"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="5">Navigation and Interaction:</font></div>

<iframe width="1241" height="698" src="https://www.youtube.com/embed/uIHPPtPBgHk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<hr
        style="width: 100%; height: 1px;">
 
<div align="left"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="5">Menus:</font></div> 


Google Earth VR maps the controls to buttons on the controller with tooltips floating nearby - as the menu options change the tooltips change.<br>
<img
        src="https://www.evl.uic.edu/aej/428/pics/googleearthvrinterface.jpg" alt="" width="800" 
        border="0"><br>
  
<iframe width="1138" height="640" src="https://www.youtube.com/embed/Fk_rLyeB8i8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<br><br>
Vanishing realms has a nice UI at the user's waist where you store keys and food and weapons and then to interact the user intersects that menu with one of the controllers as though you were reaching down to grab something off your belt.<br>
<img
        src="https://www.evl.uic.edu/aej/428/pics/vanishinginterface.png" alt="" width="800" 
        border="0"><br>
<iframe width="1672" height="856" src="https://www.youtube.com/embed/4nr98lHZj7I" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<br><br>
Tilt Brush has a nice 2-handed 3D UI where the multi-faceted menu appears in one hand and you select from it with the other hand. <br>

<img
        src="https://www.evl.uic.edu/aej/428/pics/tiltinterface.png" alt="" width="800" 
        border="0"><br>
<iframe width="1138" height="640" src="https://www.youtube.com/embed/3a6fmysCU1Q" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br><br>
Bridge Crew has a nice UI with (lots of) buttons that you have to 'press' with your virtual hands (controller) - including virtual overlay text to remind you which is which <br>

<img src="https://www.evl.uic.edu/aej/428/pics/bridgecrewinterface.jpg" alt="" width="800" 
        border="0"><br>
 
 <iframe width="1138" height="640" src="https://www.youtube.com/embed/qcwirA895jg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>       

<br><br>




<hr
        style="width: 100%; height: 1px;">
<div align="left"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="5">Voice:</font></div> 

One way to get around the complexity of the menus is to talk to the computer via a voice recognition system. <br>
However, voice commands can also be hard to learn and remember.<br>
The HoloLens makes effective use of voice to rapidly move through the menus without needing to look and pinch.<br>
Many newer MHD support voice command. <br>

 <iframe width="1198" height="674" src="https://www.youtube.com/embed/fUqnfywRBcI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>  

<hr
        style="width: 100%; height: 1px;">
<div align="left"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="5">Gesture recognition :</font></div> 
This also seems like a very natural interface. Gloves can be used to accurately track the position of the user's hand and fingers. <br>
One issue here, as with voice, is how does the computer decide that you are gesturing to it and expect something to happen, as opposed to gesturing to yourself or another person. <br><br>
   
<hr
        style="width: 100%; height: 1px;">
<div align="left"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="5">Haptics:</font></div> 
This also seems like a very natural interface. Gloves can be used to accurately track the position of the user's hand and fingers. <br>
<iframe width="1198" height="674" src="https://www.youtube.com/embed/kj3RdeJUJos" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>




<hr width="100%" size="2"><font face="Helvetica, Arial, sans-serif"><br>
    <b>References:</b> </font>
<a href="https://xinreality.com/wiki/Positional_tracking">https://xinreality.com/wiki/Positional_tracking</a><br>
<a href="https://www.nap.edu/read/4761/chapter/9#199">https://www.nap.edu/read/4761/chapter/9#199</a><br>
<a href="https://www.nap.edu/read/4761/chapter/9#189">https://www.nap.edu/read/4761/chapter/9#189</a><br>
<a href="https://www.roadtovr.com/overview-of-positional-tracking-technologies-virtual-reality/">https://www.roadtovr.com</a><br>
Some contents on this page were adapted from <a href="https://xinreality.com/wiki/Positional_tracking"> online resources</a>
</a> and Virtual and Augmented Reality class at UIC


<hr
        style="width: 100%; height: 1px;">

<div align="right"><font style="font-family:
        Helvetica,Arial,sans-serif;" color="black" size="2">&copy; Last revised: Nov 18, 2020</font></div>

</body>
</html>
